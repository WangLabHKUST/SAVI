#!/bin/bash

### default variables
outputdir=.					# output directory
java_memory=6					# memory of the Java virtual mach in Gigabytes (default: 6)
SGE_TASK_ID=0					# index of region (default: all (0))
myregion=""					# user specified region (default NULL)
mypartition=""					# user specified partition (default NULL)
pv4=0						# bool to turn on bcftools to compute pv4 (default: no)
noindeldepth=0					# bool which, if on, doesnt include include indel depth in SDP (default: no) (note: asteriks in mpileup are included irrespective of this flag)
rdplusad=0					# bool which, if on, uses RD+AD rather than SDP for total depth (default: no)
hybrid=0					# bool which, if on, uses RD+AD for first sample (normal) and SDP for total depth for all other samples (default: no)
debug=0						# bool to turn on debugging (default: no)
cleanup=1					# bool to turn on cleanup (default: yes)
filter=1					# bool to do SAVI filter (default: yes)
mapq=10						# pileup flag: skip alignments with mapQ less than (default: 10)
minad=2						# pileup2multiallele_vcf flag: min alt depth (AD) to print variant (default: 2)
s1adpp=3					# filter on S1 AD PP less than this - i.e., normal alt depth per position NOT per variant
stepstr=1245					# what steps to run (default: 1,2,4,5 - don't generate prior)
software=$( dirname $( readlink -m $0 ) )	# directory where to look for scripts
input_bams=""					# input bam files
sample_names=""					# sample names in a comma-delimited list
num_bams=2					# number of input bams (default: 2)
compsamp="2:1"					# the indices of sample to compare with savi (default: 2:1 - i.e., tumor vs norm)
cutoff=10 					# min read depth cutoff
# anngenome="GRCh37.71"				# annotating reference for SnpEff (if hg19, chrM; if GRCh37.71, chrMT)
anngenome="hg19"
noncoding=0   					# use snpEff to find only all transcripts, not just protein transcripts (default: off)
annvcf=""					# annotating vcfs in comma-delimited list (default: none)
						# common hg19 annotating vcfs in comma-delimited list
savi_present="1e-6"				# the SAVI presence posterior
savi_precision=0				# the SAVI precision, from the Hossein fix
						# required programs
required_programs="java python samtools snpEff.jar bgzip tabix vcffilter bcftools"
required_savi_programs="pileup2multiallele_vcf add_to_info make_qvt savi_poster savi_conf savi_comp savi_poster_accum savi_poster_merge savi_poster_prt savi_unif_prior savi_txt2prior"
helpmessage=$( cat <<EOF
Usage:

$0 --bam [list_of_bam_files] --ref [ref]

Required Arguments:

  --bam			comma-delimited list of bam files (order should be: normal.bam, tumor.bam) (.bai indices should be present)
  --ref			faidx-indexed ref

Options:

  --outputdir		the output directory (default: cwd)
  --region		the genomic region to run SAVI on (default: full range) (example: chr1 or chr1:1-50000000)
			If you use this flag, the index you supply becomes the file suffix.
  --index		the integer index of the region you want to run SAVI on.
			By default, 1 refers to the first chromosome in range.txt, 2 to the second, and so on.
			If you use the partition flag, 1 refers to the first partition, 2 to the second and so on.
			(default: 0, which corresponds to the full range)
  --partition		Number of bases into which to partition the genome.
			Use this flag, only if you want to break your genome into regions smaller than the chr length.
			If you use this flag, you must also specify an index. For example, 
			"--partition 50000000 --index 1" would refer to chr1:1-50000000 for hg19
			(default: not used)
  --names		sample names in a comma-delimited list (must be in the order of your bams) (default: off)
  --compsamp		comma- colon- delimited indices of samples to compare with savi (default: 2:1) (example: 2:1,3:1,3:2)
  --steps		steps to run (default: 1,2,4,5 (i.e., all except prior generation))
  --memory		the memory for the Java virtual machine in gigabytes (default: 6)
  --mindepth		the minimum read depth required in at least one sample - positions without this wont appear in pileup file (default: 5)
  --minad		min alt depth (AD) in at least one sample to output variant (default: 2)
  --mapqual		pileup flag: skip alignments with mapQ less than this (default: 30)
  --s1adpp		for filtered report, require the sample 1 (normal) alt depth per position to be less than this (default: 3) (note: this NOT S1 AD per mismatch but, rather, per position)
  --noclean		do not delete tmp intermediate files (default: off)
  --pv4			run bcftools to compute PV4 (default: off)
  --noindeldepth	do not include include indel reads in total depth count (SDP) (default: off) 
  			(note: asteriks in mpileup are included irrespective of this flag)
  --rdplusad		use reference-agreeing reads plus alternate-calling reads (RD+AD) rather than total depth (SDP) as input to savi (default: off)
  --hybrid		as input to savi, use reference-agreeing reads plus alternate-calling reads (RD+AD) for first sample (normal) and SDP for other samples (default: off)
  			(note: this flag changes read depths on positions where there are multiallelic variants)
  --debug		echo commands (default: off)
  --nofilter		do not use SAVI comparison filter (default: off) (you should use this option if NOT doing comparisons)
  --scripts		location of scripts dir (directory where this script resides - use this option only if qsub-ing)
  --ann-genome		name of the SnpEff genome with which to annotate (default: hg19)
  --noncoding		use snpEff to find all transcripts, not just only protein transcripts (default: off)
  --ann-vcf		comma-delimited list of vcfs with which to provide additional annotation (default: none)
  --buildprior		starting input prior when building the prior (default: savi/prior_unif01)
  --prior		prior to use if step3 is not run (default: savi/prior_diploid01)
  --presence		the SAVI presence posterior (default: 1e-6)
  --precision		the SAVI precision
  --help		print this message and exit

Example:

$0 --bam normal.bam,tumor.bam --outputdir . --index 1 --ref /my/ref.fasta

Notes:

This scripts assumes that $required_programs are in your PATH.
Your reference should be indexed so a .fai file resides in its directory.
Your bam files should be sorted and indexed so .bai files reside in their directories.

SAVI Steps:

  1 bams to mpileup
  2 mpileup to multiallelic vcf
  3 make prior
  4 run savi
  5 annotate with SnpEff

Variant Calling Protocol:

SAVI is *not* sufficient to get a reliable list of candidate mutations. 
Before you run SAVI, you should follow these steps:

  1 run Fastqc to check the quality of your fastq files
  2 remove low quality sequences and remove adapter contamination with Cutadapt, then re-check quality
  3 map your fastq files with bwa
  4 run Picard to remove PCR duplicates

EOF
)

# If no arguments, echo help message and quit
if [ $# == 0 ]; then
	echo "$helpmessage"
	exit;
fi

### getopts 
while [ $# -gt 0 ]; do
	if [  "$1" == "-h" -o "$1" == "-help" -o "$1" == "--help" ]; then
		shift; 
		echo "$helpmessage"
		exit;
	elif [  "$1" == "-outputdir" -o "$1" == "--outputdir" ]; then
		shift; 
		outputdir=$1; 
		shift
	elif [  "$1" == "-scripts" -o "$1" == "--scripts" ]; then
		shift; 
		software=$1; 
		shift
	elif [  "$1" == "-ref" -o "$1" == "--ref" ]; then
		shift; 
		ref=$( readlink -m $1 ); 
		shift
		if [ ! -e $ref ]; then
			echo "Cannot find the reference file:" 
			echo ${ref}
			exit 1
		fi
	elif [  "$1" == "-vcf" -o "$1" == "--vcf" ]; then
		shift; 
		vcf=$1; 
		shift
	elif [  "$1" == "-names" -o "$1" == "--names" ]; then
		shift; 
		sample_names=$1; 
		shift
	elif [  "$1" == "-compsamp" -o "$1" == "--compsamp" ]; then
		shift; 
		compsamp=$1; 
		shift
	elif [  "$1" == "-steps" -o "$1" == "--steps" ]; then
		shift; 
		stepstr=$1; 
		shift
	elif [  "$1" == "-memory" -o "$1" == "--memory" ]; then
		shift; 
		java_memory=$1;
		shift
	elif [  "$1" == "-mindepth" -o "$1" == "--mindepth" ]; then
		shift; 
		cutoff=$1;
		shift
	elif [  "$1" == "-minad" -o "$1" == "--minad" ]; then
		shift; 
		minad=$1;
		shift
	elif [  "$1" == "-mapqual" -o "$1" == "--mapqual" ]; then
		shift; 
		mapq=$1;
		shift
	elif [  "$1" == "-ag" -o "$1" == "--ann-genome" ]; then
		shift; 
		anngenome=$1;
		shift
	elif [  "$1" == "-av" -o "$1" == "--ann-vcf" ]; then
		shift; 
		annvcf=$1;
		shift
	elif [  "$1" == "-noncoding" -o "$1" == "--noncoding" ]; then
		shift; 
		noncoding=1; 
	elif [  "$1" == "-noclean" -o "$1" == "--noclean" ]; then
		shift; 
		cleanup=0; 
	elif [  "$1" == "-rdplusad" -o "$1" == "--rdplusad" ]; then
		shift; 
		rdplusad=1;
	elif [  "$1" == "-hybrid" -o "$1" == "--hybrid" ]; then
		shift; 
		hybrid=1;
	elif [  "$1" == "-noindeldepth" -o "$1" == "--noindeldepth" ]; then
		shift; 
		noindeldepth=1;
	elif [  "$1" == "-pv4" -o "$1" == "--pv4" ]; then
		shift; 
		pv4=1;
	elif [  "$1" == "-debug" -o "$1" == "--debug" ]; then
		shift; 
		debug=1; 
	elif [  "$1" == "-nofilter" -o "$1" == "--nofilter" ]; then
		shift; 
		filter=0; 
	elif [  "$1" == "-region" -o "$1" == "--region" ]; then
		shift; 
		myregion=$1; 
		shift
	elif [  "$1" == "-index" -o "$1" == "--index" ]; then
		shift; 
		SGE_TASK_ID=$1; 
		shift
	elif [  "$1" == "-partition" -o "$1" == "--partition" ]; then
		shift; 
		mypartition=$1; 
		shift
	elif [  "$1" == "-buildprior" -o "$1" == "--buildprior" ]; then
		shift; 
		buildprior=$1; 
		shift
	elif [  "$1" == "-prior" -o "$1" == "--prior" ]; then
		shift; 
		inputprior=$1; 
		shift
	elif [  "$1" == "-presence" -o "$1" == "--presence" ]; then
		shift; 
		savi_present=$1; 
		shift
	elif [  "$1" == "-precision" -o "$1" == "--precision" ]; then
		shift; 
		savi_precision=$1; 
		shift
	elif [  "$1" == "-bam" -o "$1" == "--bam" ]; then
		shift; 
		input_bams=$1; 
		# replace commas w spaces
		input_bams=$( echo $input_bams | sed 's|,| |g' ) 
		num_bams=$( echo $input_bams | wc -w )
		shift
	else	# if unknown argument, just shift
		shift
	fi
done

time1=$( date "+%s" )
buildprior=${software}/savi/prior_unif01	# input prior for building a new prior (default: savi/prior_unif01)
inputprior=${software}/savi/prior_diploid01	# input prior to use by default (default: savi/prior_unif01)

echo "[START] "`date`
echo "[pwd] "`pwd`
echo "[output directory] "$outputdir
echo "[java memory] "$java_memory
echo "[index] "$SGE_TASK_ID
echo "[partition] "$mypartition
echo "[cleanup bool] "$cleanup
echo "[pv4 bool] "$pv4
echo "[debug bool] "$debug
echo "[no indel depth bool] "$noindeldepth
echo "[RD+AD bool] "$rdplusad
echo "[hybrid bool] "$hybrid
echo "[filter] "$filter
echo "[mapq qual threshold for samtools mpileup] "$mapq
echo "[minimum alt depth (AD) to print variant] "$minad
echo "[savi steps to run] "$stepstr
echo "[software directory] "$software
echo "[input bams] "$input_bams
echo "[input prior for building prior from scratch] "$buildprior
echo "[default input prior] "$inputprior
echo "[sample names] "$sample_names
echo "[number of bams] "$num_bams
echo "[compsamp flag] "$compsamp
echo "[read depth cutoff] "$cutoff
echo "[annotating genome for snpEff] "$anngenome
echo "[annotate noncoding bool] "$noncoding
echo "[annotating list of vcfs] "$annvcf
echo "[savi presence] "$savi_present
echo "[savi precision] "$savi_precision
echo "[dependencies] "$required_programs
echo "[savi proper dependencies] "$required_savi_programs

# check for required programs
for i in $required_programs; do 
	if ! which $i > /dev/null; then
		echo "ERROR: Can't find "${i}". Please add this to your PATH and restart"; 
		exit 1
	fi;
done
for i in $required_savi_programs; do 
	if [ ! -e ${software}/savi/$i ]; then 
		echo -e "ERROR: SAVI/"${i}" not found. Please make sure you've made the binaries:\ncd SAVI/savi\nmake;"; 
		exit 1
	fi; 
done

# check for bams
for i in $input_bams; do 
	if [ ! -e ${i} ]; then 
		echo "Cannot find the bam file:"
		echo "${i}"
		exit 1
	fi; 
done

# check for reference
if [ ! -e ${ref} ]; then 
	echo "Cannot find the reference file:"
	echo "${ref}"
	exit 1
fi

# check for reference faidx-index 
if [ -e ${ref}.fai ]; then
	echo "[reference] "$ref
else
	echo "This script requires your reference to be faidx-indexed but it cannot find the file:"
	echo "${ref}.fai"
	echo
	echo "Please run:"
	echo "samtools faidx ${ref}"
	exit 1
fi

mkdir -p ${outputdir}

# turn on debugging 
if [ $debug -eq 1 ]; then
	set -eux
fi

if [ $myregion == "MT" -o $myregion == "chrMT" ]; then
	anngenome="GRCh37.71"
	echo "[alert] SnpEff annotating genome changed to "${anngenome}
fi

# if region set 
if [ ! -z "${myregion}" ]; then
	regionflag="-r ${myregion}";
	echo "[region] "$myregion
# not set
else
	if [ $SGE_TASK_ID == 0 ]; then
		regionflag="";
		echo "[region] full range"
	else
		# if partition set
		if [ ! -z "${mypartition}" ]; then
			# create a file of ranges, broken by partitions (the fancy perl stuff is just to sort the chrs by number for number-string combos)
			cat ${ref}.fai | perl -ne 'BEGIN{@myarr=()}{chomp($_); @a=split(/\t/, $_); push(@myarr, $a[0]."\t".$a[1])}END{my @sorted = map { $_->[0] } sort { $a->[1] <=> $b->[1] } map { [$_, $_=~/(\d+)/] } @myarr ; foreach $elt (@sorted) {print $elt."\n"}}' | ${software}/util/partition_genome.pl ${mypartition} > ${outputdir}/range.txt
		else
			# create a file of ranges of chrs (not broken by partitions)
			cat ${ref}.fai | perl -ne 'BEGIN{@myarr=()}{chomp($_); @a=split(/\t/, $_); push(@myarr, $a[0]."\t".$a[1])}END{my @sorted = map { $_->[0] } sort { $a->[1] <=> $b->[1] } map { [$_, $_=~/(\d+)/] } @myarr ; foreach $elt (@sorted) {print $elt."\n"}}' | cut -f1 > ${outputdir}/range.txt
		fi

		echo "[region] "$( cat ${outputdir}/range.txt | head -${SGE_TASK_ID} | tail -1 )
		regionflag="-r "$( cat ${outputdir}/range.txt | head -${SGE_TASK_ID} | tail -1 )

	fi
fi

### need to remove duplicate reads w Picard
# or else get false positives

echo -e "\nStarting Pipeline ...\n"

pileupflag="-A -B -q ${mapq} -d 100000 -L 100000 -f ${ref}"
if [[ $stepstr == *1* ]]; then
	echo "[STEP1] pileup"
	### mpileup

	# if make prior, need to generate all position mpileup (variants and non-variants)
	if [[ $stepstr == *3* ]]; then
		# for mpileup - note the -d flag: "max per-BAM depth to avoid excessive memory usage [250]." The default of 250 is way too low, so we jack it up
		# awk line - we want only lines where normal has depth > cutoff, and at least one of the tumor samples has depth > cutoff
		samtools mpileup ${pileupflag} ${regionflag} ${input_bams} \
	    		| awk -v num=${num_bams} -v cutoff=${cutoff} '{true=0; for (i = 1; i <= num-1; i++) {if ($(4+i*3) >= cutoff) {true=1}}; if (num==1 && $4 >= cutoff) {print} else if (num>1 && $4 >= cutoff && true) {print}}' > ${outputdir}/tmp_mpile.${SGE_TASK_ID}.txt

	# otherwise, just generate variants mpileup
	else
		# for mpileup - note the -d flag: "max per-BAM depth to avoid excessive memory usage [250]." The default of 250 is way too low, so we jack it up
		# awk line - we want only lines where normal has depth > cutoff, and at least one of the tumor samples has depth > cutoff
		# awk line - we also now get only variants (although this will compromise prior generation from scratch) such there's at least $minad of them (roughly - not accounting for indels properly)
		samtools mpileup ${pileupflag} ${regionflag} ${input_bams} | awk -v num=${num_bams} -v cutoff=${cutoff} -v minad=${minad} '
		{
			# reduce pileup by only printing variants

			myflag=0; # flag to print line

			# loop thro samples
			for (i = 1; i <= num-1; i++) 
			{
				# only consider if sample depth greater than or eq to cutoff
				if ($(4+i*3) >= cutoff) 
				{
					# get read string
					mystr=$(5+i*3); 
					# eliminate read starts with qual scores ACTG (e.g., stuff like ^A ^C etc)
					gsub(/\^[ACTGNactgn+-]/,"",mystr); 
					# count ACTGN mismatches
					altdepth = gsub(/[ACTGNactgn]/,"",mystr); 
					# if sufficient number of mismatches, flag line to print
					if (altdepth >= minad) 
					{
						myflag=1; break;
					}
				}
			}

			# if only one sample, print if depth >= cutoff
			if (num==1 && $4 >= cutoff) 
			{
				print;
			}

			# if multiple samples, print if sample one has depth AND myflag
			else if (num>1 && $4 >= cutoff && myflag) 
			{
				print;
			}
		}' > ${outputdir}/tmp_mpile.${SGE_TASK_ID}.txt

	fi

	# if empty
	if [ ! -s ${outputdir}/tmp_mpile.${SGE_TASK_ID}.txt ]; then
		echo "[HALT SCRIPT] pileup file is empty"
		exit 0;
	fi

	echo "[date 1] "`date`;
fi

if [[ $stepstr == *2* ]]; then
	echo "[STEP2] pileup2vcf"
	### Oscan
	# call everything, variants and non-variants alike

	if [ $noindeldepth == 0 ]; then
		# addresses a problem that samtools mpileup does not include indels in the total read count (with the exception of *s)
		# so add indel depths to SDP
		oscanflag="--cutoff ${minad} --header --includeindels";
	else
		# don't include indel reads in total depth count
		oscanflag="--cutoff ${minad} --header";
	fi

	# if make prior, need to generate all position vcf (variants and non-variants)
	if [[ $stepstr == *3* ]]; then
		# add all flag
		oscanflag=${oscanflag}" --all";

		cat ${outputdir}/tmp_mpile.${SGE_TASK_ID}.txt | ${software}/savi/pileup2multiallele_vcf $oscanflag \
		    | tee ${outputdir}/${SGE_TASK_ID}.all.vcf | awk '{ if ($0 ~ /^#/ || toupper($4) != toupper($5)) {print}}' | bgzip > ${outputdir}/${SGE_TASK_ID}.vcf.bgz

		cat ${outputdir}/${SGE_TASK_ID}.all.vcf | bgzip > ${outputdir}/${SGE_TASK_ID}.all.vcf.bgz
		rm ${outputdir}/${SGE_TASK_ID}.all.vcf

		tabix -p vcf ${outputdir}/${SGE_TASK_ID}.all.vcf.bgz

	# otherwise, just generate variants file
	else
		cat ${outputdir}/tmp_mpile.${SGE_TASK_ID}.txt | ${software}/savi/pileup2multiallele_vcf $oscanflag | bgzip > ${outputdir}/${SGE_TASK_ID}.vcf.bgz
	fi

	tabix -p vcf ${outputdir}/${SGE_TASK_ID}.vcf.bgz
	echo "[date 2] "`date`

	# if empty
	if [ $( zcat ${outputdir}/${SGE_TASK_ID}.vcf.bgz | sed '/^#/d' | head | wc -l ) == 0 ]; then
		echo "[HALT SCRIPT] vcf file is empty"
		exit 0;
	fi

	if [ $cleanup -eq 1 ]; then 
		rm -f ${outputdir}/tmp_mpile.${SGE_TASK_ID}.*
	fi

fi

if [[ $stepstr == *3* ]]; then
	echo "[STEP3] make_prior"
	### make_prior.py
	# for samples 1 through n
	#for i in $( seq 1 $num_bams ); do
	# for samples in the compsamp string
	for i in $( echo ${compsamp} | sed 's|,|\n|g; s|:|\n|g' | sort -u ); do
		mkdir -p ${outputdir}/savi/prior${i}
		${software}/make_prior.py --verbose \
		      --name s${i} \
		      --iteration 10 \
		      --prior ${buildprior} \
		      --sampleindex ${i} \
		      --outputdir ${outputdir}/savi/prior${i} \
		      --input ${outputdir}/${SGE_TASK_ID}.all.vcf.bgz;
	done;

	# if run step3, create prior string for priors specified in compsamp
	# if compsamp="2:1", it should look like this - 1:${outputdir}/savi/prior1/prior,2:${outputdir}/savi/prior2/prior
	priorstring=$( for i in $( echo ${compsamp} | sed 's|,|\n|g; s|:|\n|g' | sort -u ); do echo -n "${i}:${outputdir}/savi/prior${i}/prior,"; done | sed 's|,$||'; echo )
	echo "[date 3] "`date`;
else
	# if not step3, use diploid prior by default
	priorstring=$( for i in $( echo ${compsamp} | sed 's|,|\n|g; s|:|\n|g' | sort -u ); do echo -n "${i}:${inputprior},"; done | sed 's|,$||'; echo )
fi

if [[ $stepstr == *4* ]]; then
	echo "[STEP4] run_savi"
	### run_savi.py
	mkdir -p ${outputdir}/savi/out

	if [ $rdplusad == 1 ]; then
		# use AD+RD as tot depth
		saviflag="--rdplusad";
	elif [ $hybrid == 1 ]; then
		# use hybrid mode
		saviflag="--hybrid";
	else
		# use SDP as tot depth
		saviflag="";
	fi

	# invert filter variable
	keepfreqfile=$( echo $filter | awk '{x=$1; print !x}' )

	${software}/run_savi.py $saviflag \
	     --input ${outputdir}/${SGE_TASK_ID}.vcf.bgz \
	     --name savi_${SGE_TASK_ID} \
	     --sample ${compsamp} \
	     --prior ${priorstring} \
	     --saviprecision ${savi_precision} \
	     --savipresent ${savi_present} \
	     --keepfreqfile ${keepfreqfile} \
	     --outputdir ${outputdir}/savi/out

	# run_savi.py output files:
	# freqsavi.vcf.bgz - adds presence frequencies to all present variants 
	# finalsavi.vcf.bgz - add frequency deltas for sample comparisons to all present variants 
	# finalfilter.vcf - filter all present mutations for somatic variants

	# if savi comparisons
	if [ $filter -eq 1 ]; then 
		# unzip all present variants
		zcat ${outputdir}/savi/out/finalsavi.vcf.bgz > ${outputdir}/savi/out/finalsavi.vcf
	# if no savi comparisons (e.g., unpaired sample)
	else
		zcat ${outputdir}/savi/out/freqsavi.vcf.bgz > ${outputdir}/savi/out/finalsavi.vcf  
		rm ${outputdir}/savi/out/freqsavi.vcf.bgz ${outputdir}/savi/out/freqsavi.vcf.bgz.tbi
	fi

	# if SAVI vcf empty
	if [ $( cat ${outputdir}/savi/out/finalsavi.vcf | sed '/^#/d' | head | wc -l ) == 0 ]; then
		echo "[HALT SCRIPT] SAVI vcf file is empty"
		exit 0;
	fi

	echo "[date 4] "`date`;
fi

### SnpEff
outputdir2=${outputdir}/ann
if [[ $stepstr == *5* ]]; then
	echo "[STEP5] annotation"
	mkdir -p ${outputdir2}

	# annotate all present variants, somatic variants
	if [ $noncoding -eq 0 ]; then
		if [ -e ${outputdir}/savi/out/finalsavi.vcf ]; then
			java -Xmx${java_memory}G -jar $( which snpEff.jar ) ann ${anngenome} -noLog -q -c $( which snpEff.config ) -formatEff -noStats -lof -onlyProtein -canon -no-downstream -no-intergenic -no-upstream -no-utr ${outputdir}/savi/out/finalsavi.vcf > ${outputdir2}/tmp_${SGE_TASK_ID}.eff_0.all.vcf
		else
			java -Xmx${java_memory}G -jar $( which snpEff.jar ) ann ${anngenome} -noLog -q -c $( which snpEff.config ) -formatEff -noStats -lof -onlyProtein -canon -no-downstream -no-intergenic -no-upstream -no-utr ${outputdir}/savi/out/finalsavi.vcf.bgz > ${outputdir2}/tmp_${SGE_TASK_ID}.eff_0.all.vcf
		fi
	else
		if [ -e ${outputdir}/savi/out/finalsavi.vcf ]; then
			java -Xmx${java_memory}G -jar $( which snpEff.jar ) ann ${anngenome} -noLog -q -c $( which snpEff.config ) -formatEff -noStats -lof -canon ${outputdir}/savi/out/finalsavi.vcf > ${outputdir2}/tmp_${SGE_TASK_ID}.eff_0.all.vcf
		else
			java -Xmx${java_memory}G -jar $( which snpEff.jar ) ann ${anngenome} -noLog -q -c $( which snpEff.config ) -formatEff -noStats -lof -canon ${outputdir}/savi/out/finalsavi.vcf.bgz > ${outputdir2}/tmp_${SGE_TASK_ID}.eff_0.all.vcf
		fi
	fi

	# loop through all annotating vcfs
	myindex=1 						# define index variable for the loop
	num_vcfs=$( echo ${annvcf} | sed 's|,| |g' | wc -w )	# get the total number of annotating vcfs
	for i in $( echo ${annvcf} | sed 's|,| |g' ); do 
		# annotate all present variants
		java -Xmx${java_memory}G -jar $( which SnpSift.jar ) annotate ${i} -noLog ${outputdir2}/tmp_${SGE_TASK_ID}.eff_$(($myindex - 1)).all.vcf > ${outputdir2}/tmp_${SGE_TASK_ID}.eff_${myindex}.all.vcf

		# if cleanup, delete tmp files
		if [ $cleanup -eq 1 ]; then
			rm ${outputdir2}/tmp_${SGE_TASK_ID}.eff_$(($myindex - 1)).all.vcf
		fi

		# if final iteration of loop, convert from vcf to human readable tab-delimited report
		if [ $myindex -eq $num_vcfs ]; then

			# get useful variants and variants in the coding region. The idea is to capture these:
			# inframe_deletion *inframe_insertion frameshift_variant* initiator_codon_variant missense_variant* synonymous_variant*
			# splice_acceptor* splice_donor* splice_region* start_lost* start_gained* stop_gained* stop_lost* stop_retained_variant*
			cat ${outputdir2}/tmp_${SGE_TASK_ID}.eff_${myindex}.all.vcf | awk -F"\t" '$0 ~ /^#/ || $8 ~ /inframe|frameshift|synonymous_variant|missense_variant|splice_acceptor|splice_donor|splice_region|start|stop/' > ${outputdir2}/tmp_${SGE_TASK_ID}.eff_${myindex}.coding.vcf
			# filtering: 
			# S1 AD PP < cutoff so discard variants with normal alt depth above a certain threshhold
			# discard variants with strand bias
			# discard variants in meganormals
			# discard variants in COMMON dbSNP
			vcffilter -f "S1ADPP < ${s1adpp} & Sgt1STRANDBIAS = 0" ${outputdir2}/tmp_${SGE_TASK_ID}.eff_${myindex}.coding.vcf | awk '$0 ~ /^#/ || ( $0 !~ /MEGANORMAL_ID/ && $0 !~ /Meganormal186GBM/ && $0 !~ /COMMON\=1/)' > ${outputdir2}/tmp_${SGE_TASK_ID}.eff_${myindex}.coding.somatic.vcf

			# if sample names given, use them
			reportoptions=""
			if [ -z $sample_names ]; then 
				reportoptions="--samples $sample_names"
			fi

			# if savi comparisons
			if [ $filter -eq 1 ]; then 
				# make a string for the vcffilter - e.g., if $compsamp is 2:1,3:1,5 then $filterstring will be PD21_L > 0 | PD31_L > 0
				filterstring=$( echo $compsamp | perl -ne '{chomp($line = $_); @myarr = split(/,/, $line); foreach my $elt (@myarr) {if ($elt =~ s/://) {print "PD".$elt."_L > 0 | "}}}' | sed 's|\| $||' )
				# reverse filter
				filterstring_reverse=$( echo $compsamp | perl -ne '{chomp($line = $_); @myarr = split(/,/, $line); foreach my $elt (@myarr) {if ($elt =~ s/://) {print "PD".$elt."_U < 0 | "}}}' | sed 's|\| $||' )
				echo "[filterstring] $filterstring"
				echo "[reverse filterstring] $filterstring_reverse"
				# get somatic variants
				vcffilter -f "${filterstring}" ${outputdir2}/tmp_${SGE_TASK_ID}.eff_${myindex}.coding.somatic.vcf > ${outputdir2}/tmp_${SGE_TASK_ID}.eff_${myindex}.coding.somatic.PDfilter.vcf
				vcffilter -f "${filterstring_reverse}" ${outputdir2}/tmp_${SGE_TASK_ID}.eff_${myindex}.coding.vcf > ${outputdir2}/tmp_${SGE_TASK_ID}.eff_${myindex}.coding.rev-PDfilter.vcf

				# turn vcf into human readable, tab delimited report
				cat ${outputdir2}/tmp_${SGE_TASK_ID}.eff_${myindex}.coding.somatic.PDfilter.vcf | ${software}/util/vcf2report_for_v4.1.C.py ${reportoptions} > ${outputdir2}/report.coding.somatic.PDfilter.txt
				cat ${outputdir2}/tmp_${SGE_TASK_ID}.eff_${myindex}.coding.rev-PDfilter.vcf | ${software}/util/vcf2report_for_v4.1.C.py ${reportoptions} > ${outputdir2}/report.coding.rev-PDfilter.txt
			fi

			# turn vcf into human readable, tab delimited report
			cat ${outputdir2}/tmp_${SGE_TASK_ID}.eff_${myindex}.coding.vcf | ${software}/util/vcf2report_for_v4.1.C.py ${reportoptions} > ${outputdir2}/report.coding.txt
			cat ${outputdir2}/tmp_${SGE_TASK_ID}.eff_${myindex}.coding.somatic.vcf | ${software}/util/vcf2report_for_v4.1.C.py ${reportoptions} > ${outputdir2}/report.coding.somatic.txt
		fi

		myindex=$(($myindex + 1))

	done

	echo "[date 5] "`date`;
fi

# # Copy Number Variation
# outputdir3=${outputdir}/cnv_${SGE_TASK_ID}
# if [[ $stepstr == *6* ]]; then
# 	echo "[STEP6] copy number variation"
# 	### CNV and LOH
# 	# THIS ONLY WORKS FOR 2 SAMPLES - PAIRED TUMOR NORMAL DATA
# 
# 	mkdir -p ${outputdir3}/prior
# 
# 	cat ${outputdir}/tmp_mpile.${SGE_TASK_ID}.txt | java -Xmx${java_memory}G \
# 	    -jar $( which VarScan.v2.3.6.jar ) copynumber \
# 	    -mpileup \
# 	    ${outputdir3}/${SGE_TASK_ID}.tumor
# 
# 	cat ${outputdir3}/${SGE_TASK_ID}.tumor.copynumber | sed '1d' | awk 'BEGIN{OFS="\t"}{print "1","40",int($6+0.5),int($5+$6+0.5)}' > ${outputdir3}/${SGE_TASK_ID}.qvt.txt
# 	${software}/make_prior.py -n ${SGE_TASK_ID}.tumor -j 10 -p ${software}/savi/prior_unif01 -o ${outputdir3}/prior --qvt ${outputdir3}/${SGE_TASK_ID}.qvt.txt
# 
# 	mymean=$( cat ${outputdir3}/${SGE_TASK_ID}.qvt.txt | awk 'BEGIN{x=0}{x=x+$3/$4;}END{print x/NR}' )
# 
# 	cat ${outputdir3}/${SGE_TASK_ID}.qvt.txt | ${software}/savi/savi_poster -p ${outputdir3}/prior/prior | ${software}/savi/savi_comp 2 ${mymean} \
# 	    | awk 'BEGIN{print "cnv_call\tcnv_call_posterior"}{print}' > ${outputdir3}/${SGE_TASK_ID}.cnv.tmp.txt
# 
# 	paste ${outputdir3}/${SGE_TASK_ID}.tumor.copynumber ${outputdir3}/${SGE_TASK_ID}.cnv.tmp.txt > ${outputdir3}/${SGE_TASK_ID}.cnv.txt
# 
# 	# Loss of Heterozygosity
# 	zcat $outputdir/${SGE_TASK_ID}.vcf.bgz | ${software}/savi/make_qvt -1 -2s 2,1 \
# 	   | ${software}/savi/savi_poster -pd ${outputdir}/savi/prior2/prior ${outputdir}/savi/prior1/prior \
# 	   | ${software}/savi/savi_comp 2 0 \
# 	   | awk 'BEGIN{print "loh_call\tloh_call_posterior"}{print}' > ${outputdir3}/${SGE_TASK_ID}.loh.txt
# 
# 	echo "[date 6] "`date`;
# fi

echo "[STEP CLEANUP] clean up"
# if cleanup
if [ $cleanup -eq 1 ]; then 
	rm -f ${outputdir}/${SGE_TASK_ID}.all.vcf.bgz*
	rm -f ${outputdir}/${SGE_TASK_ID}.vcf.bgz*
	rm -f ${outputdir}/savi/out/freqsavi.vcf.bgz*
	rm -f ${outputdir3}/${SGE_TASK_ID}.qvt.txt
	rm -f ${outputdir3}/${SGE_TASK_ID}.cnv.tmp.txt
	rm -f ${outputdir3}/${SGE_TASK_ID}.tumor.copynumber
fi
# remove this because we already have the zipped version
rm -f ${outputdir}/savi/out/finalsavi.vcf

time2=$( date "+%s" )
echo "[deltat] "$(( $time2 - $time1 ))
echo "[END] "`date`
